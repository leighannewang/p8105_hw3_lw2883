p8105\_hw3\_lw2883
================
Leighanne Wang
10/6/2020

## Problem 1

``` r
data("instacart")
```

This dataset contains **1384617 rows** and **15 columns**. Observations
are on the level of items in orders by user. There are user and order
variables such as user ID, order ID, order day, and order hour. There
are also item variables such as name, aisle, department, and some
numeric codes.

*How many aisles and which aisles are most items from?*

``` r
aisle_num =    
  instacart %>% 
    count(aisle) %>% 
    arrange(desc(n)) 
```

There are **134 aisles**. Most items are ordered from the Fresh
Vegetables, Fresh Fruits, and Packaged Vegetables Fruits aisles.

*Plot showing number of items ordered in each aisle (only aisles with
more than 10,000 items ordered)*

``` r
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw3_lw2883_files/figure-gfm/instcart_plot-1.png" width="90%" />

*Table showing 3 most popular items in each of these aisles: baking
ingredients, dog food care, packaged vegetables fruits*

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

*Table showing the mean hour of the day at which Pink Lady Apples
vs. Coffee Ice Cream are ordered on each day of the week*

``` r
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) 
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

## Problem 2

*Read the accelerometer dataset. Tidy data, create weekday/weekend
variable, encode variable classes:*

``` r
accel_df =
  read_csv("./data/accel_data.csv") %>% 
    janitor::clean_names() %>% 
    pivot_longer(
      activity_1:activity_1440,
      names_to = "minute",
      names_prefix = "activity_",
      values_to = "activity_counts") %>% 
    mutate(
      minute = as.double(minute),
      day_type = recode(day, "Saturday" = "weekend", "Sunday" = "weekend", "Monday" = "weekday", "Tuesday" = "weekday", "Wednesday" = "weekday", "Thursday" = "weekday", "Friday" = "weekday")
      )
```

This dataset contains data collected from an accelerometer of a 63 year
old male with a BMI of 25 and congestive heart failure. Variables
included in this dataset are week number, day (including day ID number
and type of day), minute, and activity count for each minute of a day.
There are **50400 rows** and **6 columns**.

*Aggregate across minutes to create total activity over the day and
create table to show totals*

``` r
accel_df %>% 
  mutate(
    day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
    ) %>% 
  group_by(week, day) %>% 
  summarize(
    total_activity = sum(activity_counts)
  ) %>%
  pivot_wider(
    names_from = day,
    values_from = total_activity
  ) %>% view()
```

Looking at the total activity over the days and weeks, we see that for
the most part total activity count ranges from 300,000 to around
600,000. What is noticeable is that the last two weekends in the dataset
have less total activity count than in previous weekends, especially
Saturday which has significantly less activity count than any other day
with only 1440 total activity count.

*Single-panel plot of 24 hour activity count from accelerometer data for
each day*

``` r
accel_df %>% 
  mutate( day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
    ) %>%
  ggplot(aes(x = minute, y = activity_counts, color = day)) +
    geom_point(alpha = .7) +
    geom_line() +
    labs(
      title = "24 Hour Accelerometer Activity",
      x = "Minute of the Day",
      y = "Activity Count"
    )
```

<img src="p8105_hw3_lw2883_files/figure-gfm/accel_plot-1.png" width="90%" />

This graph shows the accelermeter activity count across the 24 hours of
a each day. Although it may be a little hard to see, this graph shows us
that there is the least amount of activity count throughout the night
which makes sense because they are most likely sleeping/resting during
this period of time. Additionally, there seems to be a jump in activity
count right before this period of low activity count during the night.
Other periods of high activity can be seen during noon on Sundays.

## Problem 3

  - separate to create year, month, day varaibles // make judgement call
    to see if you think the obs are in reasonable units // count
    snowfall for most commonly obs values
  - data manipulation then plotting step \> 2 panel one for Jan and one
    for Jul // organize data: groupby (station, year, and month) and
    summarize (average max temperature) // filter to get Jan + Jul
    either before or after groupby + summarize // plotting: average max
    temp for jan 1981,82,83.. (over years) for each station (use facet
    to get 2 panel) // structure: does it get warmer? are some stations
    always colder?
  - 2 panel plot \> since they’re completely different make 2 different
    plots then patchwork //contour plot, bin plot, hex plot for first
    plot // for second plot: filter then use distribution plot (boxplot,
    violin, ridge)
